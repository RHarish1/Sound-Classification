{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code block imports necessary libraries and modules for audio feature extraction, CNN model creation, and data preprocessing. It includes:\n",
        "\n",
        "os: for operating system-related functionalities.\n",
        "\n",
        "librosa: for audio feature extraction. \n",
        "\n",
        "numpy: for numerical operations.\n",
        "\n",
        "StratifiedKFold from sklearn.model_selection: for splitting data into train and test sets while maintaining class balance.\n",
        "\n",
        "Sequential, Conv2D, MaxPooling2D, Flatten, Dense, Dropout from tensorflow.keras.layers: for building the CNN model architecture.\n",
        "\n",
        "to_categorical from tensorflow.keras.utils: for converting class labels to categorical format.\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "This block sets up the initial environment and imports necessary tools for the subsequent cod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYJy3oaqqIft"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical,plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBDSZQJVqIfv"
      },
      "outputs": [],
      "source": [
        "# Define the base directory path to the audio dataset\n",
        "base_path = \"/path/to/audio/dataset\"\n",
        "\n",
        "# Number of cross-validation folds\n",
        "n_folds = 10\n",
        "\n",
        "# Input shape for the CNN model (assuming grayscale images)\n",
        "input_shape = (256, 256, 1)\n",
        "\n",
        "# Determine the number of classes in the dataset by counting subdirectories in the base directory\n",
        "num_classes = len(os.listdir(base_path))\n",
        "\n",
        "# Batch size for training\n",
        "batch_size = 64\n",
        "\n",
        "# Number of epochs for training the model, set a higher value for better results\n",
        "epochs = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM8A58RyqIfw"
      },
      "outputs": [],
      "source": [
        "def extract_features(file_path, n_mels=256, hop_length=1024, n_fft=4096):\n",
        "    \"\"\"\n",
        "    Extracts Mel spectrogram features from an audio file.\n",
        "    \n",
        "    Parameters:\n",
        "    - file_path: Path to the audio file.\n",
        "    - n_mels: Number of Mel frequency bins.\n",
        "    - hop_length: Number of samples between successive frames.\n",
        "    - n_fft: Number of samples used for each Fourier transform.\n",
        "    \n",
        "    Returns:\n",
        "    - mel_spec_db: Mel spectrogram feature with added channel dimension.\n",
        "    \"\"\"\n",
        "    # Load audio file using librosa\n",
        "    audio, sr = librosa.load(file_path, res_type='kaiser_fast')\n",
        "\n",
        "    # Extract Mel spectrogram feature\n",
        "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "\n",
        "    # Convert to decibels (dB)\n",
        "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "    # Resize to fixed shape (256x256) for CNN input\n",
        "    mel_spec_db = librosa.util.fix_length(mel_spec_db, size=input_shape[0], axis=1)\n",
        "\n",
        "    # Add channel dimension\n",
        "    mel_spec_db = mel_spec_db.reshape((*input_shape[:2], 1))\n",
        "\n",
        "    # Print progress information\n",
        "    print(f\"Extracted features from {file_path}\")\n",
        "\n",
        "    return mel_spec_db\n",
        "\n",
        "# Collect all audio file paths and labels\n",
        "audio_paths = []\n",
        "labels = []\n",
        "\n",
        "for label, folder in enumerate(sorted(os.listdir(base_path))):\n",
        "    folder_path = os.path.join(base_path, folder)\n",
        "    # Check if the folder is actually a directory and not a system file like .DS_Store\n",
        "    if os.path.isdir(folder_path):\n",
        "        file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.wav')]\n",
        "        audio_paths.extend(file_paths)\n",
        "        labels.extend([label] * len(file_paths))\n",
        "\n",
        "audio_paths = np.array(audio_paths)\n",
        "labels = np.array(labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyYym35PqIfx"
      },
      "outputs": [],
      "source": [
        "def create_cnn_model(num_classes):\n",
        "    \"\"\"\n",
        "    Creates a Convolutional Neural Network (CNN) model for classification.\n",
        "    \n",
        "    Parameters:\n",
        "    - num_classes: Number of classes for classification.\n",
        "    \n",
        "    Returns:\n",
        "    - model: CNN model compiled with specified optimizer, loss function, and metrics.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    # Compile the model with Adam optimizer, categorical crossentropy loss, and accuracy metric\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    # Plot the model architecture\n",
        "    plot_model(model, to_file='cnn_model.png', show_shapes=True, show_layer_names=False)\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0ShI5I9qIfx"
      },
      "outputs": [],
      "source": [
        "# Precompute and store Mel spectrogram features\n",
        "X_features = np.array([extract_features(file_path) for file_path in audio_paths])\n",
        "\n",
        "# Initialize Stratified K-Folds cross-validator\n",
        "skf = StratifiedKFold(n_splits=n_folds, shuffle=False)\n",
        "accuracy_scores = []\n",
        "\n",
        "# Iterate over each fold in the cross-validation\n",
        "for fold_idx, (train_index, test_index) in enumerate(skf.split(X_features, labels)):\n",
        "    # Split features and labels into training and testing sets\n",
        "    X_train_features, X_test_features = X_features[train_index], X_features[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "    # Convert labels to categorical\n",
        "    y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
        "    y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "    # Create and compile the CNN model\n",
        "    model = create_cnn_model(num_classes)\n",
        "    \n",
        "    # Train the CNN model on the training data\n",
        "    model.fit(X_train_features, y_train_cat, batch_size=batch_size, epochs=epochs, verbose=1)\n",
        "\n",
        "    # Evaluate the model on test data and collect accuracy\n",
        "    _, test_accuracy = model.evaluate(X_test_features, y_test_cat, verbose=0)\n",
        "    accuracy_scores.append(test_accuracy)\n",
        "\n",
        "    # Print the test accuracy for the current fold\n",
        "    print(f\"Fold {fold_idx + 1}: Test Accuracy = {test_accuracy}\")\n",
        "\n",
        "# Calculate and print average accuracy and standard deviation\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_dev = np.std(accuracy_scores)\n",
        "print(f\"Average Accuracy: {mean_accuracy:.4f} Â± {std_dev:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
